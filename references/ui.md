+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
+                           AI Risk: Estimate Your P(doom)                  +
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

          +-----------------------------------------------------+
          |                                                     |
          |         #####################################         |
          |         #  ( Placeholder: Abstract AI /      #         |
          |         #    Probability Network Graphic  )   #         |
          |         #####################################         |
          |                                                     |
          +-----------------------------------------------------+

          How likely is an AI catastrophe that ends humanity?

          P(doom) is the probability of AI causing irreversible human
          extinction within roughly the next 100 years.

          This tool guides you through key questions debated by experts
          to help you form your own estimate across different timelines.

          **Important:** This is a simplified educational model for reflection,
          based on calibrated questions. It is NOT a definitive prediction.

          Think you're ready? Let's explore the factors.


                             [ Calculate My P(doom) ]


+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++




---





=============================================================================
 Question 7 of 13                  | Progress: [|||||||.......] (54%)
=============================================================================

--- CATEGORY: Governance & Regulation ---

Your Current Estimated P(doom) Timeline:
 By 2035: [|||.......]  8.2%
 By 2050: [|||||.....] 15.5%  <-- (These values update subtly based on answers)
 By 2100: [||||||....] 23.0%

-----------------------------------------------------------------------------

 Q7: When will international treaties with effective verification
     mechanisms be established to regulate ADVANCED AI development? (?)
     Context: Global governance needed to prevent race to bottom

     Select one answer:

     ( ) 1. Before 2030
     ( ) 2. 2030-2040
     (*) 3. After 2040            <-- User selection shown with (*)
     ( ) 4. Never / >100 years

     [ < Previous Question ]                     [ Next Question > ]

=============================================================================

---



#############################################################################
#                            YOUR P(DOOM) RESULTS                           #
#############################################################################

 Your Estimated CUMULATIVE Probability of AI Existential Catastrophe:

       +-------------------------+-------------------------+
       |       Time Horizon      |       Est. P(doom)      |
       +-------------------------+-------------------------+
       | --> By 2035 (~10 yrs)   |          14.8 %         |
       | --> By 2050 (~25 yrs)   |          31.5 %         |
       | --> By 2100 (~75 yrs)   |          52.1 %         |
       +-------------------------+-------------------------+

 Risk Accumulation View:
 |--------- Period 1 (->2035) --------|--- Period 2 (->2050) ---|--- Period 3 (->2100) ---|
 |        Risk Added: 14.8%           |    Risk Added: 16.7%    |    Risk Added: 20.6%    |
 [===============---------------------|----------===============|=========================] > Time
 (Visual bar showing cumulative risk build-up)

 Interpretation: Your answers suggest a SIGNIFICANT level of concern regarding
                 AI existential risk, increasing notably in the mid-term
                 (2035-2050) and further in the long term.

------------------------ Expert Comparison (Estimate by 2100) ---------------

   You (52%) fall between Christiano (~20%) and Hinton (~60%).

   [|||||||||||||||||||||||||||||||| YOU ||||||||||||||||||||.........]
   0%   LeCun(1)  Ord(17)  Christiano(20)   Hinton(60)   Yudkowsky(99)  100%
   (Simplified scale showing your position relative to expert estimates)

------------------------ Key Drivers of Your Estimate (By 2100) -------------
 * Q1 (Autonomous Replication): 'Before 2030'        (+7.5 pts)
 * Q4 (Alignment Difficulty): 'Very unlikely (<20%)' (+9.0 pts)* Multiplied x1.5
 * Q11(Competition): 'Extreme competition'          (+6.0 pts)
 * Q7 (Intl Treaties): 'After 2040'                (+5.0 pts)

---------------------------- Share Your Insights ----------------------------

         [ Share on X/Twitter ]      [ Share on LinkedIn ]
            [ Copy Link ]             [ Download Results ]

------------------------------- Explore Further -----------------------------

         [ See Full Expert List & Details ]
         [ Learn More About AI Safety Concepts ]
         [ How This Calculator Works (Methodology) ]

#############################################################################